---
title: "Семинар 2"
author: "Многомерные статистические методы -- 1-й сем. 2020-21 гг. -- 3 курс"
date: "14.09.2020"
output:
  pdf_document:
    df_print: paged
  html_document:
    df_print: paged
lang: ru-russian
---

В этом семинаре рассмотрим основы разведочного анализа данных:

* дескриптивный анализ распределения

* визуальный анализ распределения

* статистические тесты на соответствие эмпирического распределения теоретическому

* диагностика выбросов

### Несколько вводных напоминаний о работе в R

Чтобы определить рабочую директорию текущей сессии и установить ее, где нужно, используем функции:
```{r}
getwd()
setwd('C:/Users/481/Documents/R/MSM/Sem2')
```

Для дальнейшей работы нам потребуется использовать функции, с помощью которых реализуются методы статистического анализа, из множества полезных пакетов, не встроенных в базовый набор.

Загрузить уже установленный пакет в текущую сессию:
```{r}
library('DescTools')
library('EnvStats')
library('outliers')
```

Упражняться сегодня будем на данных о ценах на квартиры в Москве и их некоторых характеристиках, размещенных ВШЭ в открытом доступе на платформе [Kaggle](https://www.kaggle.com/hugoncosta/price-of-flats-in-moscow).

Исходный файл дан в формате `csv`, размещаем его в рабочей директории. Используем стандартную функцию для чтения данных:
```{r}
data <- read.csv('flats_moscow.csv')
data
```

#### Вам нужно:

> 1. создать новую папку `МСМ_семинар_2` на рабочем столе и задать ее как рабочую директорию

> 2. установить и загрузить пакеты `DescTools`, `EnvStats`, `outliers`

> 3. загрузить данные о ценах на квартиры в Москве (файл `'flats_moscow.csv'` выслан вам на групповую почту)

Еще пара напоминаний...

* чтобы быстро получить справку о функции используем `?funcname`

* для детального ознакомления с возможностями пакета или функции обращаемся к [документации](https://www.rdocumentation.org)

* нужно вспомнить типы объектов в R, способы импорта данных, представленных в `csv` и `excel` файлах, и связанные с этим нюансы (разделители, заголовки столбцов, имена строк и пр.)

### Дескриптивный анализ распределения

Перед нами стоит задача по имеющейся обучающей выборке научиться предсказывать цены на квартиры. Предполагаем, что цена, выраженная в $1000 и обозначенная переменной `price`, зависит от таких объективных факторов:

Обозначение переменной | Переменная
------------- | -------------
totsp | общая площадь квартиры, кв.м.
livesp | жилая площадь квартиры, кв.м.
kitsp | площадь кухни, кв.м.
dist | расстояние от центра в км.
metrdist | расстояние до метро в минутах
walk | 1 – пешком от метро, 0 – на транспорте
brick | 1 – кирпичный, монолит ж/б, 0 – другой
floor | 1 – этаж кроме первого и последнего, 0 – иначе

Перед обучением модели необходимо провести предварительный анализ имеющихся данных. Многие методы в качестве предпосылки требуют близость распределения признаков к нормальному закону. Начнем с описательной статистики. 

Самое начальное представление о массиве данных:
```{r}
# структура датасета
```

Сначала рассмотрим одномерный ряд наблюдений цен, переведя $ 1 000 в 10 000 руб. по текущему курсу:
```{r}
price <- data$price*74.92/10
```

Характеристики центра:
```{r}
# средняя
mean(price)
# медиана
median(price)
# мода
Mode(price)
```

Ранговые характеристики:
```{r}
# квартили
quantile(price)
```

```{r}
# децили
quantile(price, probs=seq(0, 1, 0.1))[6]

```

Можно получить одной командой:
```{r}
# min, квартили, max
Desc(price)
```

Характеристики разброса:
```{r}
# min и max
range(price)
# дисперсия
var(price)
# стандартное отклонение
sd(price)
# интерквартильный размах
IQR(price)
# коэффициент вариации
CoefVar(price)
```

Характеристики формы:
```{r}
Skew(price)
# коэффициент асимметрии
Kurt(price)
# коэффициент эксцесса
```

Таблица описательной статистики для признаков, соотв. непрерывным случайным величинам:
```{r}
cont_data <- data[, c('price', 'totsp', 'livesp', 'kitsp', 'dist', 'metrdist')]
summaryStats(cont_data)
```

### Визуализация эмпирического распределения

```{r}
hist(price)
```

```{r}
hist(price, breaks = sqrt(length(price)), freq=FALSE)
kde <- density(price)
lines(kde, lwd=30)
# гистограмма
# ядерная оценка функции плотности
```


```{r}
# график Q-Q для теоретического нормального распределения
qqnorm(price, freq=FALSE)
```

### Статистические тесты на соответствие эмпирического распределения теоретическому

Для проверки соответствия эмпирических распределений некоторым теоретическим используются критерии согласия. Нас интересует проверка следующей гипотезы:

\[
H_0 : \text{ выборка взята из генеральной совокупности с нормальным распределением }
\]

Уже известный вам критерий согласия Пирсона:
```{r}
PearsonTest(price)
# тест Пирсона
```

Наиболее мощный по результатам исследований с помощью Монте-Карло симуляций - критерий Шапиро-Уилка:
```{r}
shapiro.test(price)
# тест Шапиро-Уилка
```

Оригинал статьи [здесь](https://www.jstor.org/stable/2333709?seq=1#metadata_info_tab_contents), более доступно идея теста и свойства [здесь](https://math.mit.edu/~rmd/465/shapiro.pdf).

### Диагностика выбросов

```{r}
# ящичковая диаграмма
boxplot(price)
```

Значения, выходящие за пределы 1.5 IQR:
```{r}
out_of_1.5IQR <- boxplot.stats(price)$out # по умолчанию 1.5 IQR
#out_of_1.5IQR <- 
```

Правило 3 IQR:
```{r}
out_of_3IQR <- boxplot.stats(price, coef=3)$out 
out_of_3IQR
```

Правило 1.5 IQR:
```{r}
bw_1.5_3IQR <- setdiff(out_of_1.5IQR, out_of_3IQR)
bw_1.5_3IQR
```

Определим номера наблюдений:
```{r}
out_of_3IQR_ind <- which(price %in% out_of_3IQR)
out_of_3IQR_ind
```

__Тест Граббса.__ Используется для проверки $H_0$ о том, что одно максимальное или минимальное наблюдение в выборке является типичным наблюдением.

```{r}
# тест Граббса - проверяется максимальное наблюдение
grubbs.test(price)
```

```{r}
# тест Граббса - проверяется минимальное наблюдение
grubbs.test(price, opposite = TRUE)

```

Все такие выделяющиеся наблюдения можно установить итеративно, пока тест не не отвергнет $H_0$.

__Тест Рознера.__ Позволяет проверить больше одного наблюдения, скажем $k$, на резкое выделение. $H_0:$ $k$ наибольших наблюдений взяты из той же генеральной совокупности, что и $(n-k)$ первых наблюдений:
```{r}
# тест Рознера
rosnerTest(price, k=10)
```

Быстро провести поверхностный разведочный анализ по массиву данных можно с использованием функции `Desc` пакета `DescTools`:
```{r}
Desc(cont_data)
```

## Самостоятельная работа:

> 1. Во сколько раз минимальная цена в сегменте 20% самых дорогих квартир превышает максимальную цену в сегменте 20% самых дешевых квартир?

Решение:
```{r}
min20 <- as.numeric(quantile(price, 0.8))
max80 <- as.numeric(quantile(price, 0.2))
min20/max80
```
По сути данная цифра лишь в несколько видоизменённом виде представляет IQR, свидетельствуя о достаточно большой разнице между квартирами из топ-20% самых дорогих и топ-20% самых дешёвых квартир выборки. 

> 2. Имеются ли основания по имеющейся выборке считать, что распределение цены на квартиру в Москве подчиняется логнормальному закону?

Указания:

+ сохраните цены в логарифмированной шкале в новый вектор

+ постройте гистограмму, Q-Q график

+ проведите тест Шапиро-Уилка

Решение:
```{r}
price_log <- log(price)
hist(price_log)
qqnorm(price_log)
shapiro.test(price_log)
```
Гистограмма свидетельствует о достаточно значительной левосторонней асимметрии, из чего можно предположить, что логарифмы цен вряд ли принадлежат нормальному распределению. 
График Q-Q также добавляет уверенности в несоответствии логарифма цен нормальному распределению, поскольку совокупность точек едва ли похожа на прямую, по диагонали пересекающую теоретические и эмпирические квантили.
Тест Шапиро-Уилка позволяет с очень высокой долей уверенности (и, соответственно, с низкой вероятностью ошибки) отвергнуть гипотезу о нормальности распределения логарифма цен. 


> 3. Определите значения робастных аналогов коэффициента вариации

Указания:

+ в качестве робастных аналогов коэффициента вариации предлагается, например [здесь](https://arxiv.org/pdf/1907.01110.pdf), использовать:
\[
RCV_Q = 0.75 \times \frac{IQR}{m}
\]
где $m$ -- медиана исходного ряда, предложен Shapiro (2005);
\[
RCV_M = 1.4826 \times \frac{MAD}{m}
\]
где $MAD = med\{ |x_i - m| \}$ -- медиана абсолютных отклонений, предложен Reimann et al. (2008), Varmuza & Filzmoser (2009).

+ используйте функцию `MAD` из пакета `DescTools`

Решение:
```{r}
RCV = CoefVar(price)
RCV_Q = 0.75*IQR(price)/median(price)
RCV_M = 1.4826*MAD(price)/median(price)
CoefVar(price)
0.75*IQR(price)/median(price)
1.4826*MAD(price)/median(price)
```
Объяснение: Видим, что робастный аналог коэффициента вариации (0,307), посчитанный через интерквартильное расстояние, достаточно сильно отклоняется от исходного коэффициента вариации (0,407), тогда как аналог, посчитанный через медиану абсолютных отклонений (0,421), отличается лишь на 2%. При этом получается, что по двум наиболее высоким коэффициентам выборка получается относительно однородной, поскольку значение превышает 33%, однако по третьему коэффициенту условия однородности выполняются. (Занятно, что в методичках Миронкиной Юлии Николаевны условие неоднородности данных выполнялось только при привышении коэффициентом единицы (100%))

> 4. Проведите эксперимент. Извлеките несколько выборок с возрастающим объемом из совокупности с нормальным распределением, добавьте к каждой по одному резко выделяющемуся наблюдению. Оцените числовые характеристики (неустойчивые и устойчивые к выбросам) по каждой из испорченных выборок и отследите зависимость эффекта засорения выборки от ее объема

Указания:

+ под "несколько" имеется ввиду довольно приличное число выборок объемами, например, от 10 до 1000 с шагом 10

+ для воспроизводимости результатов используйте `set.seed`

+ для генерирования наблюдений используйте функцию `rnorm`

+ чтобы не писать код несколько раз воспользуйтесь циклом

+ используйте функцию `append`

+ для отслеживания эффекта постройте график: по горизонтальной оси --- число наблюдений в выборке, по вертикальной --- отклонение выборочного значения от истинного

+ чтобы сделать выводы о реакции различных оценок на наличие одного выброса в зависимости от объема выборки, хорошо рассмотреть поведение отклонений для различных random seed'ов

```{r}
x = seq(10, 10000, 10)
```

```{r}
mu_vec <- c()
sd_vec <- c()
iqr_vec <- c()
MAD_vec <- c()
skew_vec <- c()
for (n in x) {
  set.seed(n)
  mu_vec <- append(mu_vec, mean(append(rnorm(n), 100)))
  sd_vec <- append(sd_vec, sd(append(rnorm(n), 100)))
  iqr_vec <- append(iqr_vec, IQR(append(rnorm(n), 100)))
  MAD_vec <- append(MAD_vec, MAD(append(rnorm(n), 100)))
  skew_vec <- append(skew_vec, Skew(append(rnorm(n), 100)))
}
```

Будем добавлять в выборку выброс в виде константы 100 на каждой итерации и взглянем на динамику характеристик распределения:
```{r}
y = mu_vec
plot(x, y, type = 'l')
```

Видно, что при увеличении количества наблюдений в выборке факт наличия выброса становится экспоненциально менее значимым.
```{r}
y = sd_vec - 1
plot(x, y, type = 'l')
```

Подобный же вывод можно сделать на основе исследования стандартного отклонения для выборок, ошибка измерения которого стремится к 0 при увеличении выборки.
```{r}
y = iqr_vec-(qnorm(0.75)-qnorm(0.25))
plot(x, y, type = 'l')
```

В свою очередь, если обратить внимание на интерквартильное расстояние, то становится очевидным, что данная устойчивая к выборсам характеристика распределения ведёт себя как затухающие колебания при увеличении числа наблюдений, где амплитуда ошибок даже при малом количестве наблюдений не превышает по модулю единицы. 
```{r}
y = MAD_vec-1
plot(x, y, type = 'l')
```

Подобная динамика наблюдается при вычислении MAD, использованного при решении предыдущей задачи.

```{r}
y = skew_vec
plot(x, y, type = 'l')
```

Очень интересная динамика наблюдается для коэффициента асимметрии, увеличивающегося при росте числа наблюдений в выборке. Это может быть объяснено тем, что чем больше наблюдений будет сосредоточено вокруг 0 в нормальном распределении, тем более левосторонней будет асимметрия относительно имеющегося единичного выброса со значением 100. Математически:
\[A_s=\frac{\mu_3}{s^3}=\frac{\frac{1}{n}\cdot\sum_{i=1}^{n}(x_i-\overline x)^3}{\sqrt{\frac{1}{n}\cdot\sum_{i=1}^{n}(x_i-\overline x)^2}^3}\]

В нашем случае математическое ожидание коэффициента асимметрии приблизетльно при увеличении n будет таково:
\[\lim\limits_{n\to \infty} E[A_s]=\lim\limits_{n\to \infty}\frac{\frac{1}{n+1}\cdot(\sum_{i=1}^{n}(0-\frac{100}{n+1})^3+(100-\frac{100}{n+1})^3)}{\sqrt{\frac{1}{n+1}\cdot(\sum_{i=1}^{n}(0-\frac{100}{n+1})^2+(100-\frac{100}{n+1})^2)}^3}=\sqrt{n+1}\cdot100\]


#### Ссылки на полезные материалы по статистическому анализу в R в открытом доступе:

1. [Шипунов А.Б., Балдин Е.М. и др. Наглядная статистика. Используем R!](http://ashipunov.info/shipunov/school/books/rbook.pdf)

2. [Мастицкий С.Э., Шитиков В.К., Статистический анализ и визуализация с помощью R](https://sociology.knu.ua/sites/default/files/library/elopen/mastitsky_and_shitikov_2014_r_tutorials.pdf)

3. [Мастицкий С.Э., Шитиков В.К., Классификация, регрессия, data-mining в R](https://ranalytics.github.io/data-mining/index.html)
