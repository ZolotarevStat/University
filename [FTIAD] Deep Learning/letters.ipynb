{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ooSfhN5t4xve","outputId":"b4810cec-bbbe-4577-b849-1b8fa1144b17"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torchvision'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43772\\854624760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"]}],"source":["import torch\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gnJRLr644Bl"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5RZD6pR6Akl"},"outputs":[],"source":["import os\n","import shutil\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bj2720Q86xy7"},"outputs":[],"source":["root = '/content/drive/MyDrive/DL'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16433g_t7EnH"},"outputs":[],"source":["Image.MAX_IMAGE_PIXELS = None\n","image = Image.open(os.path.join(root,'letters.png' )).convert('RGB')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B51qsEei7HZ6"},"outputs":[],"source":["import math\n","width, height = image.size\n","per_letter = int(math.sqrt(width*height/10000))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCGgoxe5a0FT"},"outputs":[],"source":["font_list = [\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf',\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf',\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf',\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', # мой шрифт\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf',\n","    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf',\n"," ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ig6sSruXamq"},"outputs":[],"source":["from PIL import Image, ImageDraw, ImageFont\n","import random\n","import matplotlib.pyplot as plt\n","\n","character = 'J'\n","for fnt_ in font_list:\n","  fnt = ImageFont.truetype(fnt_, 150)\n","  w, h = fnt.getsize(character)\n","\n","  img = Image.new('L', (300, 300), color='black')\n","  d = ImageDraw.Draw(img)\n","  d.text(((300-w)/2, (300-h)/2), character, font=fnt, fill=255, align=\"center\") # TO ALIGN CHARACTER IN CENTER\n","  img.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxlTFD7H9Bmn"},"outputs":[],"source":["box = (600, 600, 900, 900)\n","img2 = image.crop(box)\n","img2.show()"]},{"cell_type":"markdown","metadata":{"id":"WvEOuOoDrY37"},"source":["Эмпирическим путем обнаружили, что мой фонт - '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5jOrCgFseO9"},"outputs":[],"source":["MY_FONT = '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'"]},{"cell_type":"markdown","metadata":{"id":"sdu3u0OEF6yT"},"source":["# Генерация данных"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czlav4NE5V7B"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qu9uMPnsURif"},"outputs":[],"source":["from os.path import exists\n","import string\n","import os\n","\n","CHARACTERS = list(string.ascii_uppercase)\n","\n","class Generate_Dataset:\n","\n","  def __init__(self, SIZE, root, font_ = MY_FONT):\n","\n","    self.TINT_COLOR = (0, 0, 0)\n","    self.font_ = font_\n","    self.SIZE = SIZE\n","    self.labels = CHARACTERS\n","    self.n_classes = len(self.labels)\n","    self.ROOT = root\n","\n","  def draw_circle(self):\n","\n","    overlay = Image.new('RGBA', (300,300), self.TINT_COLOR+(0,))\n","    draw = ImageDraw.Draw(overlay)  # Create a context for drawing things on it.\n","    size = random.randint(15, 50)\n","    start1 = random.randint(0, 300-size)\n","    start2 = random.randint(0, 300-size)\n","    circle_color = (random.randint(0, 200), random.randint(0, 200), random.randint(0, 200), random.randint(50, 70))\n","    draw.ellipse(((start1, start2), (start1+size, start2+size)), fill = circle_color)\n","\n","    return overlay\n","\n","  def draw_letter(self, character):\n","    fnt = ImageFont.truetype(self.font_, size = random.randint(100,200))\n","    w, h = fnt.getsize(character)\n","\n","    img = Image.new('RGBA', (300, 300), color='white')\n","    d = ImageDraw.Draw(img)\n","    letter_color = (random.randint(0, 200), random.randint(0, 200), random.randint(0, 200))\n","    start_w = random.randint(0, 300-w)\n","    start_h = random.randint(0, 300-h)\n","\n","    d.text((start_w, start_h), character, font=fnt, fill=letter_color, align=\"center\") # TO ALIGN CHARACTER IN CENTER\n","\n","    return img\n","\n","  def get_final_pic(self, character):\n","\n","    img = self.draw_letter(character)\n","    amount = random.randint(5,30)\n","\n","    for n in range(amount):\n","      overlay = self.draw_circle()\n","      img = Image.alpha_composite(img, overlay)\n","\n","    return img\n","\n","  def gen_dataset(self):\n","\n","    class_len = self.SIZE//self.n_classes\n","    num = 0\n","\n","    for i in range(self.n_classes):\n","      path = f'{self.ROOT}/{self.labels[i]}'\n","      if not os.path.exists(path):\n","        os.mkdir(path)\n","\n","      for repeat in range(class_len):\n","        img = self.get_final_pic(self.labels[i])\n","        img = img.save(f\"{path}/{num}.png\")\n","        num+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ps3oqQRpfscb"},"outputs":[],"source":["# %%time\n","# Generate_Dataset(SIZE = 10000, root = root).gen_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4emKRVzl4gAM"},"outputs":[],"source":["class_dirs = [f'{root}/{d}' for d in os.listdir(f'{root}') if d in CHARACTERS]"]},{"cell_type":"markdown","metadata":{"id":"Sfdf_x7sF-M0"},"source":["# Загрузка данных"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dniya6IXdAcs"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","\n","class MyDataLoader(Dataset):\n","\n","  SPLIT_RANDOM_SEED = 42\n","  TEST_SIZE = 0.2\n","\n","  def __init__(self,class_dirs, train = True, transform = None):\n","\n","    super().__init__()\n","    self.train = train\n","    self.transform = transform\n","    self.to_tensor = T.ToTensor()\n","    self.all_files = []\n","    self.all_labels = []\n","    self.images = []\n","    self.classes = class_dirs\n","\n","    for i, class_name in tqdm(enumerate(self.classes), total=len(self.classes)):\n","        files = sorted(os.listdir(f'{class_name}/'))\n","        train_files, test_files = train_test_split(files, random_state=self.SPLIT_RANDOM_SEED + i,\n","                                                    test_size=self.TEST_SIZE)\n","        if self.train:\n","            self.all_files += train_files\n","            self.all_labels += [i] * len(train_files)\n","\n","        else:\n","            self.all_files += test_files\n","            self.all_labels += [i] * len(test_files)\n","\n","  def __len__(self):\n","    return len(self.all_files)\n","\n","  def __getitem__(self, item):\n","\n","    label = self.all_labels[item]\n","    filename = self.all_files[item]\n","    image = Image.open(os.path.join(self.classes[label], filename)).convert('RGBA')\n","\n","    image = image.convert(mode='RGB')\n","\n","    if self.transform is not None:\n","        image = self.transform(image)\n","\n","    return image, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ox4VCvkD-i3t"},"outputs":[],"source":["# normalize = T.Normalize(mean=[0.485, 0.456, 0.406, 0.406], std=[0.229, 0.224, 0.225, 0.225])\n","\n","train_transform = T.Compose([\n","    T.Resize(256),\n","    T.ElasticTransform(alpha=25.0),\n","    T.ToTensor(),\n","\n","    # normalize,\n","])\n","\n","test_transform = T.Compose([\n","    T.Resize(256),\n","    T.ToTensor(),\n","    # normalize,\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdHicnvn_A0w"},"outputs":[],"source":["train_dataset = MyDataLoader(class_dirs=class_dirs, train=True, transform=train_transform)\n","test_dataset = MyDataLoader(class_dirs=class_dirs, train=False, transform=test_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTrJrE1sCRX6"},"outputs":[],"source":["transform = T.ToPILImage()\n","im, lab = train_dataset[500]\n","im = transform(im)\n","im.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlOekvSQ9O5Y"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"9LhQjjBsGOlw"},"source":["# Сетка"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUUf0f3RGKP_"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tqdm.notebook import tqdm\n","\n","\n","sns.set_style('whitegrid')\n","plt.rcParams.update({'font.size': 15})\n","\n","\n","def plot_losses(train_losses, test_losses, train_accuracies, test_accuracies):\n","    clear_output()\n","    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n","    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n","    axs[0].plot(range(1, len(test_losses) + 1), test_losses, label='test')\n","    axs[0].set_ylabel('loss')\n","\n","    axs[1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train')\n","    axs[1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test')\n","    axs[1].set_ylabel('accuracy')\n","\n","    for ax in axs:\n","        ax.set_xlabel('epoch')\n","        ax.legend()\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjsrqhgeK5z9"},"outputs":[],"source":["def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n","    train_loss, train_accuracy = 0.0, 0.0\n","    model.train()\n","    for images, labels in tqdm(train_loader, desc=tqdm_desc):\n","        images = images.to(device)  # images: batch_size x num_channels x height x width\n","        labels = labels.to(device)  # labels: batch_size\n","\n","        optimizer.zero_grad()\n","        logits = model(images)  # logits: batch_size x num_classes\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * images.shape[0]\n","        train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy /= len(train_loader.dataset)\n","    return train_loss, train_accuracy\n","\n","\n","@torch.no_grad()\n","def validation_epoch(model, criterion, test_loader, tqdm_desc):\n","    test_loss, test_accuracy = 0.0, 0.0\n","    model.eval()\n","    for images, labels in tqdm(test_loader, desc=tqdm_desc):\n","        images = images.to(device)  # images: batch_size x num_channels x height x width\n","        labels = labels.to(device)  # labels: batch_size\n","        logits = model(images)  # logits: batch_size x num_classes\n","        loss = criterion(logits, labels)\n","\n","        test_loss += loss.item() * images.shape[0]\n","        test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy /= len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","\n","def train(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs):\n","    train_losses, train_accuracies = [], []\n","    test_losses, test_accuracies = [], []\n","\n","    for epoch in range(1, num_epochs + 1):\n","        train_loss, train_accuracy = training_epoch(\n","            model, optimizer, criterion, train_loader,\n","            tqdm_desc=f'Training {epoch}/{num_epochs}'\n","        )\n","        test_loss, test_accuracy = validation_epoch(\n","            model, criterion, test_loader,\n","            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n","        )\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        train_losses += [train_loss]\n","        train_accuracies += [train_accuracy]\n","        test_losses += [test_loss]\n","        test_accuracies += [test_accuracy]\n","        plot_losses(train_losses, test_losses, train_accuracies, test_accuracies)\n","\n","    return train_losses, test_losses, train_accuracies, test_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYSnpD-KGLDN"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNxehMQv6XB1"},"outputs":[],"source":["from torchvision.models import resnet18, ResNet18_Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWEgySS_7ABx"},"outputs":[],"source":["model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDmPOYCz8kTg"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4HtArP77J8F"},"outputs":[],"source":["model.fc = torch.nn.Linear(512, len(train_dataset.classes))\n","# model.conv1 = torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msAzJPdg7nmm"},"outputs":[],"source":["num_epochs = 10\n","model = model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","criterion = torch.nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdR_WJT47vAM"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsR5CHIc7r5c"},"outputs":[],"source":["num_epochs = 10\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64EG1IaAv2uP"},"outputs":[],"source":["import pickle\n","pickle.dump(model, open('model.pkl', 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"amBOYZxMOiF7"},"source":["# Разрежем большую картинку на буквы"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPXbnq1qP2dk"},"outputs":[],"source":["path = f'{root}/preds'\n","if not os.path.exists(path):\n","  os.mkdir(path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HMn56bLuwJR"},"outputs":[],"source":["# num =10000\n","# for row in range(100):\n","#   for col in range(100):\n","#     box = (row*300, col*300, (row+1)*300, (col+1)*300)\n","#     img2 = image.crop(box)\n","#     img2 = img2.rotate(-5*(col+row), Image.NEAREST, expand = 1, fillcolor = 'white')\n","#     img2 = img2.save(f\"{path}/{num}.png\")\n","#     num += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9zcjA7C0Y4k"},"outputs":[],"source":["# import shutil\n","# shutil.rmtree(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnptVCm4zb8g"},"outputs":[],"source":["path1 = f'{path}/10219.png'\n","img = Image.open(path1)\n","img.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUYYBcqiv0DE"},"outputs":[],"source":["len(os.listdir(path))"]},{"cell_type":"markdown","metadata":{"id":"tkp9ON-zGrq7"},"source":["# Предсказания"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96A3RlY5AABe"},"outputs":[],"source":["class PredsLoader(Dataset):\n","\n","  def __init__(self, preds_dir, transform = None):\n","\n","    super().__init__()\n","    self.transform = transform\n","    self.to_tensor = T.ToTensor()\n","    self.all_files = []\n","    self.images = []\n","    self.preds_dir = preds_dir\n","    self.files = sorted(os.listdir(f'{preds_dir}/'))\n","\n","    for i in tqdm(self.files, total=len(self.files)):\n","      self.all_files.append(i)\n","\n","  def __len__(self):\n","    return len(self.all_files)\n","\n","  def __getitem__(self, item):\n","\n","    filename = self.all_files[item]\n","    image = Image.open(os.path.join(self.preds_dir, filename)).convert('RGB')\n","\n","    if self.transform is not None:\n","        image = self.transform(image)\n","\n","    return image\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXMqXyN8BRLm"},"outputs":[],"source":["p = PredsLoader(preds_dir = path, transform = test_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epnR3XixBZyG"},"outputs":[],"source":["pred_loader = DataLoader(p, batch_size=8, shuffle=False, pin_memory=True, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMbYRo9UBgam"},"outputs":[],"source":["preds2 = []\n","model.eval()\n","for images in tqdm(pred_loader):\n","    images = images.to(device)  # images: batch_size x num_channels x height x width\n","    logits = model(images)  # logits: batch_size x num_classes\n","    preds2.extend(torch.argmax(logits, dim = 1).tolist())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpxL09qPMnA5"},"outputs":[],"source":["import numpy as np\n","pr = np.bincount(preds2)\n","pr = [int(p) for p in pr]\n","\n","result = dict(zip(CHARACTERS, pr))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mahwcA0Io7_c"},"outputs":[],"source":["import json\n","\n","with open('result.txt', 'w') as file:\n","     file.write(json.dumps(result))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QS9xF0A_NcTK"},"outputs":[],"source":["import pandas as pd\n","let = list(result.keys())\n","fr = list(result.values())\n","col1 = fr[0]\n","res = pd.DataFrame({'A': let[1:len(let)], str(col1): fr[1:len(fr)]})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKiQlz1JqzOX"},"outputs":[],"source":["res = res.drop(['A'], axis = 1)\n","res.to_csv(f'{root}/result.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg-9exSBtpY7"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}